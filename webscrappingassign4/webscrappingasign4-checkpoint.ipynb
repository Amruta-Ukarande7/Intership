{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "service = Service('path/to/chromedriver')  # replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the URL\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the table to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "table = wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table containing the most viewed videos and extract its rows\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows and extract the required details\n",
    "for row in rows:\n",
    "    data = row.find_all('td')\n",
    "    rank = data[0].text.strip()\n",
    "    name = data[1].text.strip()\n",
    "    artist = data[2].text.strip()\n",
    "    upload_date = data[3].text.strip()\n",
    "    views = data[4].text.strip()\n",
    "    print(rank, name, artist, upload_date, views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "service = Service('pat/to/chromedriver')  # replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the URL\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"International\" button\n",
    "international_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']//a[@href='/international']\")))\n",
    "international_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"Fixtures\" button\n",
    "fixtures_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[@href='/international/fixtures']\")))\n",
    "fixtures_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the fixtures to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "fixtures = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'js-list')))\n",
    "fixtures_html = fixtures.get_attribute('innerHTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(fixtures_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the fixtures and extract their details\n",
    "fixtures = soup.find_all('div', class_='js-list__item')\n",
    "for fixture in fixtures:\n",
    "    title = fixture.find('span', class_='u-unskewed-text').text.strip()\n",
    "    series = fixture.find('strong', class_='fixture__name').text.strip()\n",
    "    place = fixture.find('p', class_='fixture__additional-info').span.text.strip()\n",
    "    date = fixture.find('span', class_='fixture__date').text.strip()\n",
    "    time = fixture.find('span', class_='fixture__time').text.strip()\n",
    "    print(title, series, place, date, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "service = Service('C:\\Users\\Amruta Ukarande\\Downloads\\chromedriver_win32.zip')  # replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the URL\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"Economy\" button\n",
    "economy_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='dropdown'][1]/div/a\")))\n",
    "economy_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"GDP of Indian states\" link\n",
    "gdp_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='dropdown'][1]/div/div/a[3]\")))\n",
    "gdp_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the table to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "table = wait.until(EC.presence_of_element_located((By.ID, 'table_id')))\n",
    "table_html = table.get_attribute('innerHTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(table_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows of the table and extract their details\n",
    "rows = soup.find_all('tr')\n",
    "for row in rows[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    rank = cols[0].text.strip()\n",
    "    state = cols[1].text.strip()\n",
    "    gdp_18_19 = cols[2].text.strip()\n",
    "    gdp_19_20 = cols[3].text.strip()\n",
    "    share_18_19 = cols[4].text.strip()\n",
    "    gdp_billion = cols[5].text.strip()\n",
    "    print(rank, state, gdp_18_19, gdp_19_20, share_18_19, gdp_billion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Chrome browser\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Github.com\n",
    "driver.get(\"https://github.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Explore button and then on the Trending option\n",
    "explore_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Toggle navigation\"]')))\n",
    "explore_button.click()\n",
    "trending_option = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//a[contains(text(),\"Trending\")]')))\n",
    "trending_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details of the trending repositories\n",
    "trending_repos = driver.find_elements(By.XPATH, '//h1[@class=\"h3 lh-condensed\"]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in trending_repos:\n",
    "    # Get the title of the repository\n",
    "    title = repo.text\n",
    "    # Get the description of the repository\n",
    "    description = repo.get_attribute('aria-label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the repository to go to its page\n",
    "repo.click()\n",
    "# Get the number of contributors\n",
    "contributors = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//span[contains(@class,\"num text-emphasized\")]')))\n",
    "contributors_count = contributors.text\n",
    "# Get the language used in the repository\n",
    "language = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//span[@class=\"text-gray-dark text-bold mr-1\"][normalize-space()=\"Language:\"]/following-sibling::span')))\n",
    "language_used = language.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the repository\n",
    "print(\"Title:\", title)\n",
    "print(\"Description:\", description)\n",
    "print(\"Number of Contributors:\", contributors_count)\n",
    "print(\"Language Used:\", language_used)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the trending page\n",
    "driver.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a webdriver instance and open the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Charts option and then Hot 100 page link\n",
    "charts = driver.find_element_by_xpath(\"//a[@class='header__main-link header__main-link--charts']\")\n",
    "charts.click()\n",
    "time.sleep(2)\n",
    "hot100 = driver.find_element_by_xpath(\"//a[@class='charts-landing__link charts-landing__video--background']\")\n",
    "hot100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details of the top 100 songs\n",
    "song_names = []\n",
    "artist_names = []\n",
    "last_week_ranks = []\n",
    "peak_ranks = []\n",
    "weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows of the table to get the details of each song\n",
    "rows = driver.find_elements_by_xpath(\"//div[@class='chart-list__wrapper']/div\")\n",
    "for row in rows:\n",
    "    song_name = row.find_element_by_xpath(\".//span[@class='chart-list__title-text']\")\n",
    "    song_names.append(song_name.text)\n",
    "    \n",
    "    artist_name = row.find_element_by_xpath(\".//div[@class='chart-list__artist']\")\n",
    "    artist_names.append(artist_name.text)\n",
    "    \n",
    "    last_week_rank = row.find_element_by_xpath(\".//div[@class='chart-list__last-week']\")\n",
    "    last_week_ranks.append(last_week_rank.text)\n",
    "    \n",
    "    peak_rank = row.find_element_by_xpath(\".//div[@class='chart-list__rank']\")\n",
    "    peak_ranks.append(peak_rank.text)\n",
    "    \n",
    "    weeks_on_board = row.find_element_by_xpath(\".//div[@class='chart-list__weeks-on-chart']\")\n",
    "    weeks_on_board.append(weeks_on_board.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the top 100 songs\n",
    "for i in range(len(song_names)):\n",
    "    print(f\"Song Name: {song_names[i]}\")\n",
    "    print(f\"Artist Name: {artist_names[i]}\")\n",
    "    print(f\"Last Week Rank: {last_week_ranks[i]}\")\n",
    "    print(f\"Peak Rank: {peak_ranks[i]}\")\n",
    "    print(f\"Weeks on Board: {weeks_on_board[i]}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver instance\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a webdriver instance and open the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details of the highest selling novels\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publishers = []\n",
    "genres = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows of the table to get the details of each novel\n",
    "rows = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr\")\n",
    "for row in rows:\n",
    "    book_name = row.find_element_by_xpath(\".//td[2]\")\n",
    "    book_names.append(book_name.text)\n",
    "    \n",
    "    author_name = row.find_element_by_xpath(\".//td[3]\")\n",
    "    author_names.append(author_name.text)\n",
    "    \n",
    "    volumes = row.find_element_by_xpath(\".//td[4]\")\n",
    "    volumes_sold.append(volumes.text)\n",
    "    \n",
    "    publisher = row.find_element_by_xpath(\".//td[5]\")\n",
    "    publishers.append(publisher.text)\n",
    "    \n",
    "    genre = row.find_element_by_xpath(\".//td[6]\")\n",
    "    genres.append(genre.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the highest selling novels\n",
    "for i in range(len(book_names)):\n",
    "    print(f\"Book Name: {book_names[i]}\")\n",
    "    print(f\"Author Name: {author_names[i]}\")\n",
    "    print(f\"Volumes Sold: {volumes_sold[i]}\")\n",
    "    print(f\"Publisher: {publishers[i]}\")\n",
    "    print(f\"Genre: {genres[i]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver instance\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a webdriver instance and open the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details of the most watched TV series\n",
    "names = []\n",
    "year_spans = []\n",
    "genres = []\n",
    "runtimes = []\n",
    "ratings = []\n",
    "votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows of the table to get the details of each TV series\n",
    "rows = driver.find_elements_by_xpath(\"//div[@class='lister-item mode-detail']\")\n",
    "for row in rows:\n",
    "    name = row.find_element_by_xpath(\".//h3/a\")\n",
    "    names.append(name.text)\n",
    "    \n",
    "    year_span = row.find_element_by_xpath(\".//span[@class='lister-item-year text-muted unbold']\")\n",
    "    year_spans.append(year_span.text)\n",
    "    \n",
    "    genre = row.find_element_by_xpath(\".//span[@class='genre']\")\n",
    "    genres.append(genre.text)\n",
    "    \n",
    "    runtime = row.find_element_by_xpath(\".//span[@class='runtime']\")\n",
    "    runtimes.append(runtime.text)\n",
    "    \n",
    "    rating = row.find_element_by_xpath(\".//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    ratings.append(rating.text)\n",
    "    \n",
    "    vote = row.find_element_by_xpath(\".//span[@name='ir']\")\n",
    "    votes.append(vote.get_attribute('data-value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the most watched TV series\n",
    "for i in range(len(names)):\n",
    "    print(f\"Name: {names[i]}\")\n",
    "    print(f\"Year Span: {year_spans[i]}\")\n",
    "    print(f\"Genre: {genres[i]}\")\n",
    "    print(f\"Runtime: {runtimes[i]}\")\n",
    "    print(f\"Ratings: {ratings[i]}\")\n",
    "    print(f\"Votes: {votes[i]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver instance\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a webdriver instance and open the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"View All Data Sets\" link to go to the datasets page\n",
    "view_all_link = driver.find_element_by_xpath(\"//span[contains(text(),'View All Data Sets')]/parent::a\")\n",
    "view_all_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details of datasets\n",
    "names = []\n",
    "data_types = []\n",
    "tasks = []\n",
    "attribute_types = []\n",
    "no_of_instances = []\n",
    "no_of_attributes = []\n",
    "years = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows of the table to get the details of each dataset\n",
    "rows = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr\")\n",
    "for row in rows[1:]:\n",
    "    cols = row.find_elements_by_tag_name('td')\n",
    "    name = cols[0].find_element_by_tag_name('a')\n",
    "    names.append(name.text)\n",
    "    data_types.append(cols[1].text)\n",
    "    tasks.append(cols[2].text)\n",
    "    attribute_types.append(cols[3].text)\n",
    "    no_of_instances.append(cols[4].text)\n",
    "    no_of_attributes.append(cols[5].text)\n",
    "    years.append(cols[6].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the datasets\n",
    "for i in range(len(names)):\n",
    "    print(f\"Dataset Name: {names[i]}\")\n",
    "    print(f\"Data Type: {data_types[i]}\")\n",
    "    print(f\"Task: {tasks[i]}\")\n",
    "    print(f\"Attribute Type: {attribute_types[i]}\")\n",
    "    print(f\"No. of Instances: {no_of_instances[i]}\")\n",
    "    print(f\"No. of Attributes: {no_of_attributes[i]}\")\n",
    "    print(f\"Year: {years[i]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver instance\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company\n",
    "D)Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a webdriver instance and open the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the \"Recruiters\" link to go to the recruiters page\n",
    "recruiters_link = driver.find_element_by_xpath(\"//a[contains(text(),'Recruiters')]\")\n",
    "recruiters_link.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the new tab that opens after clicking the \"Recruiters\" link\n",
    "driver.switch_to.window(driver.window_handles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for \"Data Science\" in the search bar and click on the search button\n",
    "search_bar = driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_bar.send_keys(\"Data Science\")\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the search results to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details of recruiters\n",
    "names = []\n",
    "designations = []\n",
    "companies = []\n",
    "skills = []\n",
    "locations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the pages of search results to get the details of each recruiter\n",
    "while True:\n",
    "    # Get the rows of the table on the current page\n",
    "    rows = driver.find_elements_by_xpath(\"//div[@class='recInfo']/div[1]\")\n",
    "    for row in rows:\n",
    "        name = row.find_element_by_tag_name('a')\n",
    "        names.append(name.text)\n",
    "        designation = row.find_element_by_xpath(\"./following-sibling::div[1]\")\n",
    "        designations.append(designation.text)\n",
    "        company = row.find_element_by_xpath(\"./following-sibling::div[2]\")\n",
    "        companies.append(company.text)\n",
    "        skill = row.find_element_by_xpath(\"./following-sibling::div[3]\")\n",
    "        skills.append(skill.text)\n",
    "        location = row.find_element_by_xpath(\"./following-sibling::div[4]\")\n",
    "        locations.append(location.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a \"Next\" button to go to the next page of search results\n",
    "next_button = driver.find_elements_by_xpath(\"//div[@class='pagination']/a[text()='Next']\")\n",
    "if len(next_button) == 0:\n",
    "        break\n",
    "else:\n",
    "    next_button[0].click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the recruiters\n",
    "for i in range(len(names)):\n",
    "    print(f\"Name: {names[i]}\")\n",
    "    print(f\"Designation: {designations[i]}\")\n",
    "    print(f\"Company: {companies[i]}\")\n",
    "    print(f\"Skills: {skills[i]}\")\n",
    "    print(f\"Location: {locations[i]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver instance\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
